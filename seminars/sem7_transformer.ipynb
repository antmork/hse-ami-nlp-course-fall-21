{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"sem7_transformer.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"bqLJ1rXXgyJF"},"source":["## Attention"]},{"cell_type":"markdown","metadata":{"id":"fkuT7RZSgyJP"},"source":["* Кодирование производится с помощью BiLSTM (не принципиально)\n","* Веса $a_i$ обычно в сумме равны $1$"]},{"cell_type":"markdown","metadata":{"id":"MOrJ5UJ3gyJc"},"source":["<img src=\"images/attention.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"]},{"cell_type":"markdown","metadata":{"id":"zXCrXvr1gyJs"},"source":["Визуализируя веса, можно понимать стратегию получения результата (от каких частей контекста зависела каждая из частей выхода).\n"]},{"cell_type":"markdown","metadata":{"id":"pmvzeKz4gyJ4"},"source":["Пример визуализации весов $attention$ в задаче машинного перевода"]},{"cell_type":"markdown","metadata":{"id":"SJ3HmOJ2gyKB"},"source":["<img src=\"images/attention_matrix.png\" alt=\"Drawing\" style=\"width: 480px;\"/>"]},{"cell_type":"markdown","metadata":{"id":"-fUQbenDgyKJ"},"source":["При использовании BiLSTM каждый вектор $h_j$ хранит информацию о всей последовательности, но в наибольшей степени о $j$-м слове и его соседях.\n"]},{"cell_type":"markdown","metadata":{"id":"FJLwQ_7ygyKg"},"source":["Далее при текущем выходе $y_{t−1}$ (с вектором $s_{t−1}$) для вектора каждого входного слова $h_j$ считается $a_{tj}$ – вклад в генерацию следующего выходного вектора ($attention$):\n","\n","$$a_{tj} = \\frac {e^{e_{tj}}} {\\sum_k e^{e_{tk}}}$$\n","\n","где $e_{tj} = f (s_{t−1}, h_j )$ – модель выравнивания"]},{"cell_type":"markdown","metadata":{"id":"yfQJ1BwegyKp"},"source":["\n","􏰀Модель выравнивания предсказывает, насколько хорошо соотносятся входное слово в позиции j и выходное в позиции t (обычно это простая модель, например, однослойная сеть)"]},{"cell_type":"markdown","metadata":{"id":"EAaLLix7gyKu"},"source":["#### Multi-head attention"]},{"cell_type":"markdown","metadata":{"id":"UQOndzS6gyK1"},"source":["Вход: вектор запроса и несколько пар векторов ключей и значений (ключ и значение обычно совпадают)"]},{"cell_type":"markdown","metadata":{"id":"dGsSZHGqgyK8"},"source":["<img src=\"images/multi-head-attention.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"]},{"cell_type":"markdown","metadata":{"id":"d9uhfIHCgyLB"},"source":["Для запроса и каждого ключа считается вес (линейный слой)\n","Значения суммируются с этими весами в итоговый вектор"]},{"cell_type":"markdown","metadata":{"id":"qrOVDqPhgyLK"},"source":["Идея: обучать несколько $attention$, в надежде, что они станут отвечать за разные признаки слов"]},{"cell_type":"markdown","metadata":{"id":"QMv3Lze2gyLQ"},"source":["Результаты пропустим через однослойную сеть, получим на выходе один вектор той же размерности, что и входные вектора."]},{"cell_type":"markdown","metadata":{"id":"Xlf2w8jxgyLV"},"source":["## Transformer"]},{"cell_type":"markdown","metadata":{"id":"QoloG2FjgyLc"},"source":["Состоит из encoder и decoder, в каждом используются $multi$-$head\\ attention$ и полносвязные (свёрточные) слои (нет RNN)"]},{"cell_type":"markdown","metadata":{"id":"Cq0-EgBzgyLi"},"source":["Для каждого слова в encoder формируется вектор на основе нескольких слоёв $multi$-$head\\ attention$, который передаётся в декодер."]},{"cell_type":"markdown","metadata":{"id":"Sh0BSuXIgyLo"},"source":["\n","􏰀На основании векторов энкодера, а также выходных векторов для уже обработанных слов получается вектор для текущего слова. В обоих случаях используется $multi$-$head\\ attention$."]},{"cell_type":"markdown","metadata":{"id":"kRB7CygRgyLw"},"source":["<img src=\"images/transformer.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"]},{"cell_type":"markdown","metadata":{"id":"2jrB3KrEgyL2"},"source":["$Positional\\ encoding$ – дополнительный вектор признаков для каждого слова, представляющий собой набор значений синусов и косинусов с разными периодами от позиции слова в предложении"]},{"cell_type":"markdown","metadata":{"id":"Olz_dkF7gyMJ"},"source":["В трансформере и в encoder, и в decoder можно использовать несколько последовательных слоёв $multi$-$head\\ attention$."]},{"cell_type":"markdown","metadata":{"id":"6hUIwQsogyMR"},"source":["Для большей выразительности и качества добавляют полносвязные слои, а также дропаут, нормализацию по слою и residual connections."]},{"cell_type":"markdown","metadata":{"id":"rpRtUxBCgyMW"},"source":["Важная особенность: обучение модели внутри предложения можно распараллелить, в отличие от RNN."]},{"cell_type":"markdown","metadata":{"id":"LVxPlZjTgyMb"},"source":["## BERT"]},{"cell_type":"markdown","metadata":{"id":"SPm1Z70CgyMh"},"source":["$BERT\\ (Bidirectional\\ Encoder\\ Representations\\ from\\ Transformers)\\ -$ многослойный двунаправленный transformer-encoder."]},{"cell_type":"markdown","metadata":{"id":"zLOQhanQgyMl"},"source":["#### Model architecture "]},{"cell_type":"markdown","metadata":{"id":"nG68JJD5gyMr"},"source":["Модель BERT основана на архитектуре Transformer и является усовершенствованием модели GPT от OpenAI.\n","Модель, в отличие от GPT, является двунаправленной.\n","\n","Ссылка на оригинальную статью: https://arxiv.org/abs/1810.04805"]},{"cell_type":"markdown","metadata":{"id":"quD9SMdrgyMx"},"source":["<img src=\"images/bert_model.png\" alt=\"Drawing\" style=\"width: 550px;\"/>"]},{"cell_type":"markdown","metadata":{"id":"n53CZgqfgyM6"},"source":["Основные параметры модели:\n","* L – количество $transformer$-блоков \n","* H – размер скрытого представления,\n","* A – количество параллельных слоев в $multi$-$head$ $attention$"]},{"cell_type":"markdown","metadata":{"id":"II4ZP4mLgyNC"},"source":["Существует две основные модели от Google:\n","\n","* $BERT_{BASE}$: \n","    * L = 12\n","    * H = 768\n","    * A = 12, \n","    * Total = 110M\n","$$$$\n","* $BERT_{LARGE}$: \n","    * L = 24\n","    * H = 1024\n","    * A = 16, \n","    * Total = 340M\n"]},{"cell_type":"markdown","metadata":{"id":"XRQzUaShgyNJ"},"source":["Модель обучается на двух задачах: \n","* Masked Language Modeling.\n","* Next sentence prediction."]},{"cell_type":"markdown","metadata":{"id":"zGe1nHSxgyNP"},"source":["#### Masked Language Modeling"]},{"cell_type":"markdown","metadata":{"id":"ZxtHoUZmgyNV"},"source":["В отличие от обычного Language Modeling, где предсказывается каждое следующее слово на каждом шаге, в задаче Masked Language Modeling случайные токены заменяются на специальный токен [MASK] и предсказываются только эти \"замаскированные\" токены."]},{"cell_type":"markdown","metadata":{"id":"0S6a_1lAgyNb"},"source":["* 80% времени обучения: Заменим слово на [MASK].\n","    * my dog is hairy → my dog is [MASK]\n","* 10% времени обучения: Заменим слово на другое случайное слово \n","    * my dog is hairy → my dog is apple\n","* 10% времени обучения: оставим предложение без изменений. Цель этого - сделать модель смещенной в сторону слова, которое действительно встречалось в корпусе в данном предложении. \n","    * my dog is hairy → my dog is hairy. "]},{"cell_type":"markdown","metadata":{"id":"DezfQpjQgyNi"},"source":["#### Next sentence prediction "]},{"cell_type":"markdown","metadata":{"id":"AvdEev9hgyNm"},"source":["Next sentence prediction $-$ задача бинарной классификации. По паре предложений требуется определить, является ли второе предложение продолжением первого."]},{"cell_type":"markdown","metadata":{"id":"5j1k_iyygyNq"},"source":["* Input =[CLS] the man went to [MASK] store [SEP] he bought a gallon [MASK] milk [SEP]\n","    * Label = IsNext\n","$$$$\n","* Input =[CLS] the man [MASK] to the store [SEP] penguin [MASK] are flight ##less birds [SEP]\n","    * Label = NotNext"]},{"cell_type":"markdown","metadata":{"id":"9IlAkN5cgyNt"},"source":["#### BERT Embeddings"]},{"cell_type":"markdown","metadata":{"id":"JUdLxHbAgyN1"},"source":["Посмотрим на эмбеддинги, получаемые с помощью модели BERT. \n","\n","Будем использовать модель $BERT_{base}$ из реализации pytorch_pretrained_bert от HuggingFace. \n","Ссылка на их гитхаб: https://github.com/huggingface/transformers"]},{"cell_type":"markdown","metadata":{"id":"X_lfT9MSgyN5"},"source":["Примеры текстов взяты из туториала (https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/)"]},{"cell_type":"code","metadata":{"id":"mm8eIVafgyOA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634843467003,"user_tz":-180,"elapsed":35908,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04607260023147477501"}},"outputId":"7165df4e-0591-4d7c-8744-6f8cfc02a456"},"source":["import torch\n","!pip install -q pytorch_pretrained_bert\n","from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n","\n","# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n","import logging\n","#logging.basicConfig(level=logging.INFO)\n","\n","import matplotlib.pyplot as plt\n","# % matplotlib inline\n","\n","# Load pre-trained model tokenizer (vocabulary)\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 123 kB 5.3 MB/s \n","\u001b[K     |████████████████████████████████| 131 kB 38.5 MB/s \n","\u001b[K     |████████████████████████████████| 79 kB 7.3 MB/s \n","\u001b[K     |████████████████████████████████| 8.0 MB 36.7 MB/s \n","\u001b[K     |████████████████████████████████| 138 kB 51.5 MB/s \n","\u001b[K     |████████████████████████████████| 127 kB 37.5 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[?25h"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 231508/231508 [00:00<00:00, 1930846.40B/s]\n"]}]},{"cell_type":"code","metadata":{"id":"Jf9OKnYkgyOn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634843485048,"user_tz":-180,"elapsed":358,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04607260023147477501"}},"outputId":"f538f9cf-8ec7-433c-af6c-3d681f14c939"},"source":["text = \"Here is the sentence I want embeddings for.\"\n","#text = \"Предложение на русском\"\n","text = \"After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\"\n","marked_text = \"[CLS] \" + text + \" [SEP]\"\n","\n","print (marked_text)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["[CLS] After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank. [SEP]\n"]}]},{"cell_type":"code","metadata":{"id":"LX3S-pZZgyPD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634843497709,"user_tz":-180,"elapsed":465,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04607260023147477501"}},"outputId":"e7d08932-886d-46ce-deb6-29183551c421"},"source":["tokenized_text = tokenizer.tokenize(marked_text)\n","print (tokenized_text)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["['[CLS]', 'after', 'stealing', 'money', 'from', 'the', 'bank', 'vault', ',', 'the', 'bank', 'robber', 'was', 'seen', 'fishing', 'on', 'the', 'mississippi', 'river', 'bank', '.', '[SEP]']\n"]}]},{"cell_type":"code","metadata":{"id":"mBQr_8oUgyPj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634843501181,"user_tz":-180,"elapsed":411,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04607260023147477501"}},"outputId":"30ff6d8a-878f-459b-e52a-9971bc4615ff"},"source":["list(tokenizer.vocab.keys())[5000:5020]\n"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['knight',\n"," 'lap',\n"," 'survey',\n"," 'ma',\n"," '##ow',\n"," 'noise',\n"," 'billy',\n"," '##ium',\n"," 'shooting',\n"," 'guide',\n"," 'bedroom',\n"," 'priest',\n"," 'resistance',\n"," 'motor',\n"," 'homes',\n"," 'sounded',\n"," 'giant',\n"," '##mer',\n"," '150',\n"," 'scenes']"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"K_Qrm-TkgyQJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634843510159,"user_tz":-180,"elapsed":285,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04607260023147477501"}},"outputId":"f812a77b-74e4-4839-8d70-751aac1e95d0"},"source":["indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n","\n","for tup in zip(tokenized_text, indexed_tokens):\n","    print (tup)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["('[CLS]', 101)\n","('after', 2044)\n","('stealing', 11065)\n","('money', 2769)\n","('from', 2013)\n","('the', 1996)\n","('bank', 2924)\n","('vault', 11632)\n","(',', 1010)\n","('the', 1996)\n","('bank', 2924)\n","('robber', 27307)\n","('was', 2001)\n","('seen', 2464)\n","('fishing', 5645)\n","('on', 2006)\n","('the', 1996)\n","('mississippi', 5900)\n","('river', 2314)\n","('bank', 2924)\n","('.', 1012)\n","('[SEP]', 102)\n"]}]},{"cell_type":"code","metadata":{"id":"lsVwMc4DgyQu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634843525323,"user_tz":-180,"elapsed":389,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04607260023147477501"}},"outputId":"28874ff9-76e2-42be-e0c3-59dda8a78395"},"source":["segments_ids = [1] * len(tokenized_text)\n","print (segments_ids)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"]}]},{"cell_type":"code","metadata":{"id":"00LvTZQ4gyRJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634843561091,"user_tz":-180,"elapsed":31259,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04607260023147477501"}},"outputId":"7d3d990e-b0ff-41dd-9874-ee68ff0b70f6"},"source":["# Convert inputs to PyTorch tensors\n","tokens_tensor = torch.tensor([indexed_tokens])\n","segments_tensors = torch.tensor([segments_ids])\n","\n","# Load pre-trained model (weights)\n","model = BertModel.from_pretrained('bert-base-uncased')\n","\n","# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n","model.eval()"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 407873900/407873900 [00:22<00:00, 18471012.53B/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): BertLayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"QbKyUT2pgyRj","executionInfo":{"status":"ok","timestamp":1634843577269,"user_tz":-180,"elapsed":622,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04607260023147477501"}}},"source":["# Predict hidden states features for each layer\n","with torch.no_grad():\n","    encoded_layers, _ = model(tokens_tensor, segments_tensors)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"wde48HNngySB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634843582042,"user_tz":-180,"elapsed":279,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04607260023147477501"}},"outputId":"344d8a4d-5ce3-4653-b74f-a60226f2cf96"},"source":["print (\"Number of layers:\", len(encoded_layers))\n","layer_i = 0\n","\n","print (\"Number of batches:\", len(encoded_layers[layer_i]))\n","batch_i = 0\n","\n","print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n","token_i = 0\n","\n","print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of layers: 12\n","Number of batches: 1\n","Number of tokens: 22\n","Number of hidden units: 768\n"]}]},{"cell_type":"code","metadata":{"id":"QZY_8deMgySp","colab":{"base_uri":"https://localhost:8080/","height":592},"executionInfo":{"status":"ok","timestamp":1634843599968,"user_tz":-180,"elapsed":971,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04607260023147477501"}},"outputId":"4de88a09-3dcf-449c-a137-2e3fbbba1565"},"source":["# For the 5th token in our sentence, select its feature values from layer 5.\n","token_i = 5\n","layer_i = 5\n","vec = encoded_layers[layer_i][batch_i][token_i]\n","\n","# Plot the values as a histogram to show their distribution.\n","plt.figure(figsize=(10,10))\n","plt.hist(vec, bins=200)\n","plt.show()"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x720 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"lKiq2k9KgyTE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634843613673,"user_tz":-180,"elapsed":272,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04607260023147477501"}},"outputId":"72b435a6-c0c5-43a6-e4ba-a0c9960df45e"},"source":["# Convert the hidden state embeddings into single token vectors\n","\n","# Holds the list of 12 layer embeddings for each token\n","# Will have the shape: [# tokens, # layers, # features]\n","token_embeddings = [] \n","\n","# For each token in the sentence...\n","for token_i in range(len(tokenized_text)):\n","  \n","  # Holds 12 layers of hidden states for each token \n","    hidden_layers = [] \n","  \n","  # For each of the 12 layers...\n","    for layer_i in range(len(encoded_layers)):\n","    \n","    # Lookup the vector for `token_i` in `layer_i`\n","        vec = encoded_layers[layer_i][batch_i][token_i]\n","\n","        hidden_layers.append(vec)\n","    \n","    token_embeddings.append(hidden_layers)\n","\n","# Sanity check the dimensions:\n","print (\"Number of tokens in sequence:\", len(token_embeddings))\n","print (\"Number of layers per token:\", len(token_embeddings[0]))"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of tokens in sequence: 22\n","Number of layers per token: 12\n"]}]},{"cell_type":"code","metadata":{"id":"wIYuLdIngyTc","executionInfo":{"status":"ok","timestamp":1634843649772,"user_tz":-180,"elapsed":348,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04607260023147477501"}}},"source":["concatenated_last_4_layers = [torch.cat((layer[-1], layer[-2], layer[-3], layer[-4]), 0) for layer in token_embeddings] # [number_of_tokens, 3072]\n","\n","summed_last_4_layers = [torch.sum(torch.stack(layer)[-4:], 0) for layer in token_embeddings] # [number_of_tokens, 768]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"NMMfRmoFgyT4","executionInfo":{"status":"ok","timestamp":1634843651411,"user_tz":-180,"elapsed":4,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04607260023147477501"}}},"source":["sentence_embedding = torch.mean(encoded_layers[11], 1)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"BONBKH7NgyUK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634843654807,"user_tz":-180,"elapsed":11,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04607260023147477501"}},"outputId":"f934b770-e25f-4319-a688-0459746b93d7"},"source":["print (\"Our final sentence embedding vector of shape:\"), sentence_embedding[0].shape[0]"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Our final sentence embedding vector of shape:\n"]},{"output_type":"execute_result","data":{"text/plain":["(None, 768)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"8gbRvUPZgyUn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634843657659,"user_tz":-180,"elapsed":326,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04607260023147477501"}},"outputId":"8a2fa1c4-691f-4278-ca28-e5fe7bdc1146"},"source":["print (text)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\n"]}]},{"cell_type":"code","metadata":{"id":"e3cas3jngyU-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634843664279,"user_tz":-180,"elapsed":273,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04607260023147477501"}},"outputId":"96806dc7-8d18-4ff1-a333-dfda55c9f214"},"source":["for i,x in enumerate(tokenized_text):\n","    print (i,x)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["0 [CLS]\n","1 after\n","2 stealing\n","3 money\n","4 from\n","5 the\n","6 bank\n","7 vault\n","8 ,\n","9 the\n","10 bank\n","11 robber\n","12 was\n","13 seen\n","14 fishing\n","15 on\n","16 the\n","17 mississippi\n","18 river\n","19 bank\n","20 .\n","21 [SEP]\n"]}]},{"cell_type":"code","metadata":{"id":"oe1UZW4NgyVT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634843672017,"user_tz":-180,"elapsed":266,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04607260023147477501"}},"outputId":"50b7233a-0adf-4113-90bb-280a74b67cd9"},"source":["print (\"First fifteen values of 'bank' as in 'bank robber':\")\n","summed_last_4_layers[10][:15]"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["First fifteen values of 'bank' as in 'bank robber':\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([ 1.1868, -1.5298, -1.3770,  1.0648,  3.1446,  1.4003, -4.2407,  1.3946,\n","        -0.1170, -1.8777,  0.1091, -0.3862,  0.6744,  2.1924, -4.5306])"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"LClp-L3-gyVn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634843680479,"user_tz":-180,"elapsed":270,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04607260023147477501"}},"outputId":"172c4df2-cf5f-4ee2-e234-a1b8674778ef"},"source":["print (\"First fifteen values of 'bank' as in 'bank vault':\")\n","summed_last_4_layers[6][:15]"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["First fifteen values of 'bank' as in 'bank vault':\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([ 2.1319, -2.1413, -1.6260,  0.8638,  3.3173,  0.1796, -4.4853,  3.1215,\n","        -0.9740, -3.1780,  0.1046, -1.5481,  0.4758,  1.1703, -4.4859])"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"xUG33MxygyWE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634843694981,"user_tz":-180,"elapsed":267,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04607260023147477501"}},"outputId":"3b6ad2ca-a09e-47f5-b6b3-ac9e52507fd5"},"source":["print (\"First fifteen values of 'bank' as in 'river bank':\")\n","summed_last_4_layers[19][:15]"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["First fifteen values of 'bank' as in 'river bank':\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([ 1.1295, -1.4724, -0.7296, -0.0901,  2.4970,  0.5330,  0.9742,  5.1834,\n","        -1.0692, -1.5941,  1.9261,  0.7119, -0.9809,  1.2127, -2.9812])"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"Gox0H8x_gyWY","executionInfo":{"status":"ok","timestamp":1634843698941,"user_tz":-180,"elapsed":1189,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04607260023147477501"}}},"source":["from sklearn.metrics.pairwise import cosine_similarity\n","\n","# Compare \"bank\" as in \"bank robber\" to \"bank\" as in \"river bank\"\n","different_bank = cosine_similarity(summed_last_4_layers[10].reshape(1,-1), summed_last_4_layers[19].reshape(1,-1))[0][0]\n","\n","# Compare \"bank\" as in \"bank robber\" to \"bank\" as in \"bank vault\" \n","same_bank = cosine_similarity(summed_last_4_layers[10].reshape(1,-1), summed_last_4_layers[6].reshape(1,-1))[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"OOkVqOtLgyWs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634843724110,"user_tz":-180,"elapsed":297,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04607260023147477501"}},"outputId":"574dc52d-a36a-46a0-cfad-11ce09011488"},"source":["print (\"Similarity of 'bank' as in 'bank robber' to 'bank' as in 'bank vault':\",  same_bank)"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Similarity of 'bank' as in 'bank robber' to 'bank' as in 'bank vault': 0.9456752\n"]}]},{"cell_type":"code","metadata":{"id":"XWho3QZLgyW-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634843726000,"user_tz":-180,"elapsed":258,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04607260023147477501"}},"outputId":"cde69c31-6193-4516-9abc-13b32a55f69e"},"source":["print (\"Similarity of 'bank' as in 'bank robber' to 'bank' as in 'river bank':\",  different_bank)"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Similarity of 'bank' as in 'bank robber' to 'bank' as in 'river bank': 0.67973334\n"]}]},{"cell_type":"code","metadata":{"id":"xwsAcLNFgyXP"},"source":[""],"execution_count":null,"outputs":[]}]}