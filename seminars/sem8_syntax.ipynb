{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "sem5_syntax.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nRK4rz_4Rui"
      },
      "source": [
        "# Depencency parsing\n",
        "(парсинг зависимостей)\n",
        "\n",
        "### Что это?\n",
        "\n",
        "* наша цель -- представить предложение естественного языка в виде дерева\n",
        "* слова предложения -- вершины; *зависимости (dependencies)* между ними -- рёбра\n",
        "* зависимости могут быть разными: например, субъект глагола, объект глагола, прилагательное-модификатор и так далее\n",
        "\n",
        "### Формат\n",
        "\n",
        "Существует несколько форматов записи деревьев зависимостей, но самый популярный и общеиспользуемый -- [CoNLL-U](http://universaldependencies.org/format.html).<br/>\n",
        "Как это выглядит (пример из [русского Universal Dependency трибанка](https://github.com/UniversalDependencies/UD_Russian-SynTagRus)):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okBwf_PmodX1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGPJZErN4Rur"
      },
      "source": [
        "my_example = \"\"\"\n",
        "# sent_id = 2003Armeniya.xml_138\n",
        "# text = Перспективы развития сферы высоких технологий.\n",
        "1\tПерспективы\tперспектива\tNOUN\t_\tAnimacy=Inan|Case=Nom|Gender=Fem|Number=Plur\t0\tROOT\t0:root\t_\n",
        "2\tразвития\tразвитие\tNOUN\t_\tAnimacy=Inan|Case=Gen|Gender=Neut|Number=Sing\t1\tnmod\t1:nmod\t_\n",
        "3\tсферы\tсфера\tNOUN\t_\tAnimacy=Inan|Case=Gen|Gender=Fem|Number=Sing\t2\tnmod\t2:nmod\t_\n",
        "4\tвысоких\tвысокий\tADJ\t_\tCase=Gen|Degree=Pos|Number=Plur\t5\tamod\t5:amod\t_\n",
        "5\tтехнологий\tтехнология\tNOUN\t_\tAnimacy=Inan|Case=Gen|Gender=Fem|Number=Plur\t3\tnmod\t3:nmod\tSpaceAfter=No\n",
        "6\t.\t.\tPUNCT\t_\t_\t1\tpunct\t1:punct\t_\n",
        "\"\"\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMzTO66x4RvQ"
      },
      "source": [
        "Комментарии + таблица c 9 колонками (разделители табы):\n",
        "* ID\n",
        "* FORM: токен\n",
        "* LEMMA: начальная форма\n",
        "* UPOS: универсальная часть речи\n",
        "* XPOS: лингво-специфичная часть речи\n",
        "* FEATS: морфологическая информация: падеж, род, число etc\n",
        "* HEAD: id ролителя\n",
        "* DEPREL: тип зависимости, то есть отношение к токену-родителю\n",
        "* DEPS: альтернативный подграф (не будем углубляться :))\n",
        "* MISC: всё остальное\n",
        "\n",
        "Отсутствующие данные представляются с помощью `_`. Больше подробностей про формат -- в [официальной документации](http://universaldependencies.org/format.html).<br>\n",
        "User-friendly визуализация: ![2003Armeniya.xml_138]\n",
        "(rus_tree.png)\n",
        "\n",
        "Отрытый инструмент для визуализации, ручной разметки и конвертации в другие форматы: UD Annotatrix. [Online-интерфейс](https://universal-dependencies.linghub.net/annotatrix), [репозиторий](https://github.com/jonorthwash/ud-annotatrix).\n",
        "\n",
        "Трибанк -- много таких предложений. Обычно они разделяются двумя переносами строки.\n",
        "### Как считывать данные в питоне\n",
        "\n",
        "Используем библиотеку [conllu](https://github.com/EmilStenstrom/conllu)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtYwvxU94Rvf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e0d18c5-1250-43ab-b0cb-8a44eee1f40e"
      },
      "source": [
        "!pip3 install conllu"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting conllu\n",
            "  Downloading conllu-4.4.1-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: conllu\n",
            "Successfully installed conllu-4.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyt3asU34Rv8"
      },
      "source": [
        "from conllu import parse"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk68zTQh4RwU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ecccc8a-c33d-437d-ff9c-d40398f6da67"
      },
      "source": [
        "help(parse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function parse in module conllu:\n",
            "\n",
            "parse(data: str, fields: Union[Sequence[str], NoneType] = None, field_parsers: Dict[str, Callable[[List[str], int], Any]] = None, metadata_parsers: Union[Dict[str, Callable[[str, Union[str, NoneType]], Any]], NoneType] = None) -> List[conllu.models.TokenList]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h02Fm3c-4Rwp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "197f26c1-6233-41b7-f5a1-fdff1176bd93"
      },
      "source": [
        "sentences = parse(my_example)\n",
        "sentence = sentences[0]\n",
        "sentence[0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'deprel': 'ROOT',\n",
              " 'deps': [('root', 0)],\n",
              " 'feats': {'Animacy': 'Inan',\n",
              "  'Case': 'Nom',\n",
              "  'Gender': 'Fem',\n",
              "  'Number': 'Plur'},\n",
              " 'form': 'Перспективы',\n",
              " 'head': 0,\n",
              " 'id': 1,\n",
              " 'lemma': 'перспектива',\n",
              " 'misc': None,\n",
              " 'upos': 'NOUN',\n",
              " 'xpos': None}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoNoYEgd4Rw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5daac8e-9f2a-42c0-a36b-23ad132769b7"
      },
      "source": [
        "sentence[-1]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'deprel': 'punct',\n",
              " 'deps': [('punct', 1)],\n",
              " 'feats': None,\n",
              " 'form': '.',\n",
              " 'head': 1,\n",
              " 'id': 6,\n",
              " 'lemma': '.',\n",
              " 'misc': None,\n",
              " 'upos': 'PUNCT',\n",
              " 'xpos': None}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjMb8xbF4RxU"
      },
      "source": [
        "## Визуализация\n",
        "\n",
        "В nltk есть DependencyGraph, который умеет рисовать деревья (и ещё многое другое). Для того чтобы визуализация работала корректно, ему нужна зависимость: graphviz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3jlN-RL4RxY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ed3f5a2-d348-4aba-98a0-102f73643280"
      },
      "source": [
        "!apt-get install graphviz\n",
        "!pip install graphviz"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.40.1-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (0.10.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AaUGIvP4Rxo"
      },
      "source": [
        "from nltk import DependencyGraph"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhsUcFUi4Rx_"
      },
      "source": [
        "В отличие от `conllu`, `DependencyGraph` не справляется с комментариями, поэтому придётся их убрать. Кроме того ему обязательно нужен `deprel` *ROOT* в верхнем регистре, иначе он не находит корень."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj9J2O9_4RyE"
      },
      "source": [
        "sents = []\n",
        "for sent in my_example.split('\\n\\n'):\n",
        "    # убираем коменты\n",
        "    sent = '\\n'.join([line for line in sent.split('\\n') if not line.startswith('#')])\n",
        "    # заменяем deprel для root\n",
        "    sent = sent.replace('\\troot\\t', '\\tROOT\\t')\n",
        "    sents.append(sent)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNom0yYz4Ryf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "7c7955a9-5426-4682-b5b8-70ef84b54fa0"
      },
      "source": [
        "graph = DependencyGraph(tree_str=sents[0])\n",
        "graph"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DependencyGraph with 7 nodes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"180pt\" height=\"479pt\"\n viewBox=\"0.00 0.00 179.50 479.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 475)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-475 175.5,-475 175.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<text text-anchor=\"middle\" x=\"98.5\" y=\"-449.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 (None)</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<text text-anchor=\"middle\" x=\"98.5\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 (Перспективы)</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M98.5,-434.9735C98.5,-423.1918 98.5,-407.5607 98.5,-394.1581\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"102.0001,-394.0033 98.5,-384.0034 95.0001,-394.0034 102.0001,-394.0033\"/>\n<text text-anchor=\"middle\" x=\"118.5\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ROOT</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<text text-anchor=\"middle\" x=\"53.5\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2 (развития)</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M89.176,-347.9735C82.9009,-335.8418 74.5148,-319.6287 67.4499,-305.9698\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"70.5151,-304.2776 62.8121,-297.0034 64.2976,-307.4935 70.5151,-304.2776\"/>\n<text text-anchor=\"middle\" x=\"96.5\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n</g>\n<!-- 6 -->\n<g id=\"node4\" class=\"node\">\n<title>6</title>\n<text text-anchor=\"middle\" x=\"144.5\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">6 (.)</text>\n</g>\n<!-- 1&#45;&gt;6 -->\n<g id=\"edge3\" class=\"edge\">\n<title>1&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M108.0312,-347.9735C114.4457,-335.8418 123.0182,-319.6287 130.2401,-305.9698\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"133.4008,-307.4797 134.981,-297.0034 127.2126,-304.2077 133.4008,-307.4797\"/>\n<text text-anchor=\"middle\" x=\"140\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">punct</text>\n</g>\n<!-- 3 -->\n<g id=\"node5\" class=\"node\">\n<title>3</title>\n<text text-anchor=\"middle\" x=\"53.5\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">3 (сферы)</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M53.5,-260.9735C53.5,-249.1918 53.5,-233.5607 53.5,-220.1581\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"57.0001,-220.0033 53.5,-210.0034 50.0001,-220.0034 57.0001,-220.0033\"/>\n<text text-anchor=\"middle\" x=\"70.5\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<text text-anchor=\"middle\" x=\"53.5\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">5 (технологий)</text>\n</g>\n<!-- 3&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>3&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M53.5,-173.9735C53.5,-162.1918 53.5,-146.5607 53.5,-133.1581\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"57.0001,-133.0033 53.5,-123.0034 50.0001,-133.0034 57.0001,-133.0033\"/>\n<text text-anchor=\"middle\" x=\"70.5\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n</g>\n<!-- 4 -->\n<g id=\"node7\" class=\"node\">\n<title>4</title>\n<text text-anchor=\"middle\" x=\"53.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">4 (высоких)</text>\n</g>\n<!-- 5&#45;&gt;4 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M53.5,-86.9735C53.5,-75.1918 53.5,-59.5607 53.5,-46.1581\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"57.0001,-46.0033 53.5,-36.0034 50.0001,-46.0034 57.0001,-46.0033\"/>\n<text text-anchor=\"middle\" x=\"70\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">amod</text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcAHBYIp4RzD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "446dbe28-df73-45a0-dc69-1c5892a698a1"
      },
      "source": [
        "tree = graph.tree()\n",
        "print(tree.pretty_print())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Перспективы           \n",
            "  _______|__________       \n",
            " |               развития \n",
            " |                  |      \n",
            " |                сферы   \n",
            " |                  |      \n",
            " |              технологий\n",
            " |                  |      \n",
            " .               высоких  \n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rj0Pfkt4Rzn"
      },
      "source": [
        "## UDPipe\n",
        "\n",
        "Есть разные инструменты для парсинга зависимостей. Сегодня мы посмотрим на [UDPipe](http://ufal.mff.cuni.cz/udpipe). UDPipe умеет парсить текст с помощью готовых моделей (которые можно скачать [здесь](https://github.com/jwijffels/udpipe.models.ud.2.0/tree/master/inst/udpipe-ud-2.0-170801)) и обучать модели на своих трибанках.\n",
        "\n",
        "Собственно, в UDPipe есть три вида моделей:\n",
        "* токенизатор (разделить текст на предложения, предложения на токены, сделать заготовку для CoNLL-U)\n",
        "* тэггер (лемматизировать, разметить части речи)\n",
        "* сам парсер (проставить каждому токену `head` и `deprel`)\n",
        "\n",
        "Мы сегодня не будем обучать новых моделей (это слишком долго), а используем готовую модель для русского."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLpwSiLy4Rzt"
      },
      "source": [
        "### The Python binding\n",
        "\n",
        "У udpipe есть питоновская обвязка. Она довольно [плохо задокументирована](https://pypi.org/project/ufal.udpipe/), но зато можно использовать прямо в питоне :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyYOIA_m4Rz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "192a2cd5-40a0-4184-cfe7-c600bbe01381"
      },
      "source": [
        "!pip install ufal.udpipe"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ufal.udpipe\n",
            "  Downloading ufal.udpipe-1.2.0.3.tar.gz (304 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 23.7 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 28.2 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 51 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 61 kB 37.2 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 71 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 81 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 92 kB 32.7 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 102 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 112 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 122 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 133 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 143 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 153 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 163 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 174 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 184 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 194 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 204 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 215 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 225 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 235 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 245 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 256 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 266 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 276 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 286 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 296 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 304 kB 28.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: ufal.udpipe\n",
            "  Building wheel for ufal.udpipe (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ufal.udpipe: filename=ufal.udpipe-1.2.0.3-cp37-cp37m-linux_x86_64.whl size=5626573 sha256=3c13b19d2d8acf22c0518185ddf68c9883064c4189c04d4ae914f11be6c57d62\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/b5/8e/3da091629a21ce2d10bf90759d0cb034ba10a5cf7a01e83d64\n",
            "Successfully built ufal.udpipe\n",
            "Installing collected packages: ufal.udpipe\n",
            "Successfully installed ufal.udpipe-1.2.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql1BTybu4R0Y"
      },
      "source": [
        "from ufal.udpipe import Model, Pipeline"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXN2mwek4R0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b2f9d75-8ed6-4c02-a289-0939bec98fbd"
      },
      "source": [
        "!wget https://github.com/jwijffels/udpipe.models.ud.2.0/raw/master/inst/udpipe-ud-2.0-170801/russian-ud-2.0-170801.udpipe"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-08 08:42:32--  https://github.com/jwijffels/udpipe.models.ud.2.0/raw/master/inst/udpipe-ud-2.0-170801/russian-ud-2.0-170801.udpipe\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/jwijffels/udpipe.models.ud.2.0/master/inst/udpipe-ud-2.0-170801/russian-ud-2.0-170801.udpipe [following]\n",
            "--2021-11-08 08:42:32--  https://raw.githubusercontent.com/jwijffels/udpipe.models.ud.2.0/master/inst/udpipe-ud-2.0-170801/russian-ud-2.0-170801.udpipe\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13265262 (13M) [application/octet-stream]\n",
            "Saving to: ‘russian-ud-2.0-170801.udpipe’\n",
            "\n",
            "russian-ud-2.0-1708 100%[===================>]  12.65M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2021-11-08 08:42:32 (184 MB/s) - ‘russian-ud-2.0-170801.udpipe’ saved [13265262/13265262]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kz82sDSs4R1g"
      },
      "source": [
        "model = Model.load(\"russian-ud-2.0-170801.udpipe\") # path to the model"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBaOZ0b34R17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d68e74dd-1e97-431c-ff4d-74843d13779e"
      },
      "source": [
        "# если успех, должно быть так (model != None)\n",
        "model"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Swig Object of type 'model *' at 0x7faf0b27aeb0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaecspKG4R2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c88672e3-5b8a-409d-9771-75dab7b0e3d4"
      },
      "source": [
        "pipeline = Pipeline(model, 'generic_tokenizer', '', '', '')\n",
        "example = \"Эти типы стали есть в цеху.\"\n",
        "parsed = pipeline.process(example)\n",
        "print(parsed)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# newdoc\n",
            "# newpar\n",
            "# sent_id = 1\n",
            "# text = Эти типы стали есть в цеху.\n",
            "1\tЭти\tЭТОТ\tDET\tDT\tAnimacy=Inan|Case=Nom|Number=Plur\t2\tdet\t_\t_\n",
            "2\tтипы\tТИП\tNOUN\tNN\tAnimacy=Inan|Case=Nom|Gender=Masc|Number=Plur\t4\tnsubj\t_\t_\n",
            "3\tстали\tСТАТЬ\tAUX\tVBC\tAspect=Perf|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin\t4\taux:pass\t_\t_\n",
            "4\tесть\tБЫТЬ\tVERB\tVBC\tAspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t0\troot\t_\t_\n",
            "5\tв\tВ\tADP\tIN\t_\t6\tcase\t_\t_\n",
            "6\tцеху\tцеху\tNOUN\tNN\tAnimacy=Inan|Case=Acc|Gender=Fem|Number=Sing\t4\tobl\t_\tSpaceAfter=No\n",
            "7\t.\t.\tPUNCT\t.\t_\t4\tpunct\t_\tSpacesAfter=\\n\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpulUcWF4R2w"
      },
      "source": [
        "Как видим, UDPipe и токенизировал, и лематизировал текст, сделал POS-tagging и, собственно, синтаксический парсинг."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F4vP19n4R21"
      },
      "source": [
        "### Command line interface\n",
        "\n",
        "Но с обвязкой бывают проблемы, и вообще довольно удобно пользоваться прекомпилированной утилитой `udpipe` из шелла."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW8TjFxo4R25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c41eb2c3-8a49-419a-ad12-ca87a58e17b7"
      },
      "source": [
        "!wget https://github.com/ufal/udpipe/releases/download/v1.2.0/udpipe-1.2.0-bin.zip"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-08 08:46:31--  https://github.com/ufal/udpipe/releases/download/v1.2.0/udpipe-1.2.0-bin.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/50672597/a24cacd8-77c6-11e7-8f6e-e9de8ca37f48?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211108%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211108T084631Z&X-Amz-Expires=300&X-Amz-Signature=de9c6145c0bd73842407a50180b53b6ea13c939330f6711e331a31b375383ea5&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=50672597&response-content-disposition=attachment%3B%20filename%3Dudpipe-1.2.0-bin.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-11-08 08:46:31--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/50672597/a24cacd8-77c6-11e7-8f6e-e9de8ca37f48?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211108%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211108T084631Z&X-Amz-Expires=300&X-Amz-Signature=de9c6145c0bd73842407a50180b53b6ea13c939330f6711e331a31b375383ea5&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=50672597&response-content-disposition=attachment%3B%20filename%3Dudpipe-1.2.0-bin.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12644197 (12M) [application/octet-stream]\n",
            "Saving to: ‘udpipe-1.2.0-bin.zip’\n",
            "\n",
            "udpipe-1.2.0-bin.zi 100%[===================>]  12.06M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-11-08 08:46:32 (196 MB/s) - ‘udpipe-1.2.0-bin.zip’ saved [12644197/12644197]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KtEq2H04R3S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3429054f-173a-49bb-914a-e0423db4e811"
      },
      "source": [
        " !unzip udpipe-1.2.0-bin.zip"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  udpipe-1.2.0-bin.zip\n",
            "   creating: udpipe-1.2.0-bin/\n",
            "   creating: udpipe-1.2.0-bin/bin-linux32/\n",
            "   creating: udpipe-1.2.0-bin/bin-linux32/csharp/\n",
            "   creating: udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/\n",
            "   creating: udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/\n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/Trainer.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/Evaluator.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/InputFormat.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/Comments.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/EmptyNodes.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/MultiwordToken.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/Sentences.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/udpipe_csharp.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/Pipeline.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/Words.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/Version.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/Children.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/MultiwordTokens.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/udpipe_csharpPINVOKE.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/EmptyNode.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/Model.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/Word.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/Sentence.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/ProcessingError.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/Token.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/csharp/Ufal/UDPipe/OutputFormat.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/csharp/libudpipe_csharp.so  \n",
            "   creating: udpipe-1.2.0-bin/bin-linux32/java/\n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/java/libudpipe_java.so  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/java/udpipe.jar  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux32/udpipe  \n",
            "  inflating: udpipe-1.2.0-bin/MANUAL.html  \n",
            "  inflating: udpipe-1.2.0-bin/MANUAL  \n",
            "  inflating: udpipe-1.2.0-bin/INSTALL  \n",
            "   creating: udpipe-1.2.0-bin/bin-linux64/\n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/udpipe  \n",
            "   creating: udpipe-1.2.0-bin/bin-linux64/java/\n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/java/udpipe.jar  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/java/libudpipe_java.so  \n",
            "   creating: udpipe-1.2.0-bin/bin-linux64/csharp/\n",
            "   creating: udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/\n",
            "   creating: udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/\n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/Sentence.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/MultiwordTokens.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/InputFormat.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/Word.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/EmptyNode.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/Children.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/Version.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/udpipe_csharpPINVOKE.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/ProcessingError.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/EmptyNodes.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/Words.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/Evaluator.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/MultiwordToken.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/Model.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/Pipeline.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/udpipe_csharp.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/Comments.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/OutputFormat.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/Trainer.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/Token.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/csharp/Ufal/UDPipe/Sentences.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-linux64/csharp/libudpipe_csharp.so  \n",
            "   creating: udpipe-1.2.0-bin/bin-osx/\n",
            "   creating: udpipe-1.2.0-bin/bin-osx/csharp/\n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/csharp/libudpipe_csharp.dylib  \n",
            "   creating: udpipe-1.2.0-bin/bin-osx/csharp/Ufal/\n",
            "   creating: udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/\n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/EmptyNodes.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/EmptyNode.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/Trainer.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/InputFormat.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/Children.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/Word.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/Sentence.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/udpipe_csharpPINVOKE.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/Words.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/ProcessingError.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/Version.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/udpipe_csharp.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/MultiwordToken.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/Evaluator.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/Model.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/Comments.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/MultiwordTokens.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/Sentences.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/OutputFormat.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/Pipeline.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/csharp/Ufal/UDPipe/Token.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/udpipe  \n",
            "   creating: udpipe-1.2.0-bin/bin-osx/java/\n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/java/libudpipe_java.dylib  \n",
            "  inflating: udpipe-1.2.0-bin/bin-osx/java/udpipe.jar  \n",
            "  inflating: udpipe-1.2.0-bin/MANUAL.pdf  \n",
            "   creating: udpipe-1.2.0-bin/bindings/\n",
            "  inflating: udpipe-1.2.0-bin/bindings/README.PERL  \n",
            "   creating: udpipe-1.2.0-bin/bindings/perl/\n",
            "  inflating: udpipe-1.2.0-bin/bindings/perl/std_common.i  \n",
            "  inflating: udpipe-1.2.0-bin/bindings/perl/perlstrings.swg  \n",
            "  inflating: udpipe-1.2.0-bin/bindings/perl/Makefile  \n",
            "   creating: udpipe-1.2.0-bin/bindings/perl/examples/\n",
            "  inflating: udpipe-1.2.0-bin/bindings/perl/examples/run_udpipe.pl  \n",
            "  inflating: udpipe-1.2.0-bin/bindings/perl/udpipe_perl.i  \n",
            "  inflating: udpipe-1.2.0-bin/bindings/README.CS  \n",
            "  inflating: udpipe-1.2.0-bin/bindings/README.PYTHON  \n",
            "  inflating: udpipe-1.2.0-bin/bindings/README.JAVA  \n",
            "   creating: udpipe-1.2.0-bin/bindings/common/\n",
            "  inflating: udpipe-1.2.0-bin/bindings/common/udpipe.i  \n",
            "  inflating: udpipe-1.2.0-bin/bindings/common/udpipe_stl.i  \n",
            "  inflating: udpipe-1.2.0-bin/bindings/common/Makefile.common  \n",
            "   creating: udpipe-1.2.0-bin/bindings/java/\n",
            "  inflating: udpipe-1.2.0-bin/bindings/java/udpipe_java.i  \n",
            "   creating: udpipe-1.2.0-bin/bindings/java/examples/\n",
            "  inflating: udpipe-1.2.0-bin/bindings/java/examples/RunUDPipe.java  \n",
            "  inflating: udpipe-1.2.0-bin/bindings/java/examples/Makefile  \n",
            "  inflating: udpipe-1.2.0-bin/bindings/java/Makefile  \n",
            "   creating: udpipe-1.2.0-bin/bindings/csharp/\n",
            "  inflating: udpipe-1.2.0-bin/bindings/csharp/udpipe_csharp.i  \n",
            "  inflating: udpipe-1.2.0-bin/bindings/csharp/Makefile  \n",
            "   creating: udpipe-1.2.0-bin/bindings/csharp/examples/\n",
            "  inflating: udpipe-1.2.0-bin/bindings/csharp/examples/RunUDPipe.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bindings/csharp/examples/Makefile  \n",
            "   creating: udpipe-1.2.0-bin/bindings/python/\n",
            "  inflating: udpipe-1.2.0-bin/bindings/python/Makefile  \n",
            "  inflating: udpipe-1.2.0-bin/bindings/python/udpipe_python.i  \n",
            "   creating: udpipe-1.2.0-bin/bindings/python/examples/\n",
            "  inflating: udpipe-1.2.0-bin/bindings/python/examples/run_udpipe.py  \n",
            "  inflating: udpipe-1.2.0-bin/bindings/python/examples/udpipe_model.py  \n",
            "  inflating: udpipe-1.2.0-bin/bindings/python/pystrings.swg  \n",
            "   creating: udpipe-1.2.0-bin/bin-win32/\n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/udpipe.exe  \n",
            "   creating: udpipe-1.2.0-bin/bin-win32/java/\n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/java/udpipe.jar  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/java/udpipe_java.dll  \n",
            "   creating: udpipe-1.2.0-bin/bin-win32/csharp/\n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/csharp/udpipe_csharp.dll  \n",
            "   creating: udpipe-1.2.0-bin/bin-win32/csharp/Ufal/\n",
            "   creating: udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/\n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/MultiwordTokens.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/Version.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/MultiwordToken.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/Token.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/Sentences.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/Children.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/Model.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/Sentence.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/ProcessingError.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/Evaluator.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/Words.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/Trainer.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/udpipe_csharpPINVOKE.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/InputFormat.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/EmptyNodes.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/Comments.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/OutputFormat.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/udpipe_csharp.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/Word.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/EmptyNode.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win32/csharp/Ufal/UDPipe/Pipeline.cs  \n",
            "   creating: udpipe-1.2.0-bin/bin-win64/\n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/udpipe.exe  \n",
            "   creating: udpipe-1.2.0-bin/bin-win64/csharp/\n",
            "   creating: udpipe-1.2.0-bin/bin-win64/csharp/Ufal/\n",
            "   creating: udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/\n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/udpipe_csharpPINVOKE.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/ProcessingError.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/Version.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/Evaluator.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/Children.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/Sentence.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/Sentences.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/MultiwordTokens.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/udpipe_csharp.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/Model.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/EmptyNode.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/EmptyNodes.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/Trainer.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/Word.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/Words.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/Comments.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/Token.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/Pipeline.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/MultiwordToken.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/OutputFormat.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/csharp/Ufal/UDPipe/InputFormat.cs  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/csharp/udpipe_csharp.dll  \n",
            "   creating: udpipe-1.2.0-bin/bin-win64/java/\n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/java/udpipe.jar  \n",
            "  inflating: udpipe-1.2.0-bin/bin-win64/java/udpipe_java.dll  \n",
            "  inflating: udpipe-1.2.0-bin/LICENSE  \n",
            "  inflating: udpipe-1.2.0-bin/AUTHORS  \n",
            "  inflating: udpipe-1.2.0-bin/README  \n",
            "   creating: udpipe-1.2.0-bin/src/\n",
            "  inflating: udpipe-1.2.0-bin/src/Makefile.builtem  \n",
            "   creating: udpipe-1.2.0-bin/src/tokenizer/\n",
            "  inflating: udpipe-1.2.0-bin/src/tokenizer/detokenizer.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/tokenizer/morphodita_tokenizer_wrapper.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/tokenizer/detokenizer.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/tokenizer/morphodita_tokenizer_wrapper.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/tokenizer/multiword_splitter.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/tokenizer/multiword_splitter.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/tokenizer/multiword_splitter_trainer.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/tokenizer/multiword_splitter_trainer.h  \n",
            "   creating: udpipe-1.2.0-bin/src/sentence/\n",
            "  inflating: udpipe-1.2.0-bin/src/sentence/empty_node.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/sentence/sentence.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/sentence/output_format.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/sentence/token.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/sentence/multiword_token.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/sentence/word.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/sentence/input_format.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/sentence/input_format.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/sentence/output_format.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/sentence/token.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/sentence/sentence.h  \n",
            "   creating: udpipe-1.2.0-bin/src/rest_server/\n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/udpipe_service.h  \n",
            "   creating: udpipe-1.2.0-bin/src/rest_server/microrestd/\n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/pugixml.h  \n",
            "   creating: udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/\n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/rest_request.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/version.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/xml_builder.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/rest_server.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/xml_response_generator.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/json_response_generator.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/json_builder.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/rest_service.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/rest_server.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/xml_builder.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/xml_response_generator.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/response_generator.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/json_response_generator.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/version.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/json_builder.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/rest_server/string_piece.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/AUTHORS  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/CHANGES  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/README  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/Makefile.include  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/microrestd.h  \n",
            "   creating: udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/\n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/connection.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/microhttpd.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/internal.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/autoinit_funcs.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/platform.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/README  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/w32functions.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/AUTHORS  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/memorypool.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/MHD_config.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/daemon.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/internal.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/postprocessor.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/reason_phrase.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/COPYING  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/response.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/reason_phrase.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/tsearch.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/connection.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/response.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/memorypool.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/w32functions.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/libmicrohttpd/platform_interface.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/LICENSE  \n",
            "   creating: udpipe-1.2.0-bin/src/rest_server/microrestd/pugixml/\n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/pugixml/pugixml.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/pugixml/pugixml.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/pugixml/README  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/pugixml/AUTHORS  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/pugixml/pugiconfig.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/microrestd/pugixml/LICENSE  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/udpipe_service.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/rest_server/udpipe_server.cpp  \n",
            "   creating: udpipe-1.2.0-bin/src/parsito/\n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/Makefile.include  \n",
            "   creating: udpipe-1.2.0-bin/src/parsito/tree/\n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/tree/tree_format_conllu.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/tree/tree.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/tree/tree_format.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/tree/tree_format.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/tree/tree.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/tree/node.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/tree/tree_format_conllu.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/AUTHORS  \n",
            "   creating: udpipe-1.2.0-bin/src/parsito/embedding/\n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/embedding/embedding_encode.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/embedding/embedding.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/embedding/embedding.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/CHANGES  \n",
            "   creating: udpipe-1.2.0-bin/src/parsito/version/\n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/version/version.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/version/version.cpp  \n",
            "   creating: udpipe-1.2.0-bin/src/parsito/configuration/\n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/configuration/value_extractor.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/configuration/node_extractor.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/configuration/configuration.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/configuration/value_extractor.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/configuration/configuration.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/configuration/node_extractor.h  \n",
            "   creating: udpipe-1.2.0-bin/src/parsito/network/\n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/network/activation_function.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/network/network_parameters.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/network/neural_network_trainer.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/network/neural_network_trainer.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/network/neural_network.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/network/neural_network.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/LICENSE  \n",
            "   creating: udpipe-1.2.0-bin/src/parsito/transition/\n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/transition/transition_system_projective.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/transition/transition.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/transition/transition_system_swap.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/transition/transition_system_link2.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/transition/transition_system_link2.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/transition/transition_system_projective.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/transition/transition_system.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/transition/transition_system.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/transition/transition_system_swap.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/transition/transition_oracle.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/transition/transition.h  \n",
            "   creating: udpipe-1.2.0-bin/src/parsito/parser/\n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/parser/parser_nn_trainer.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/parser/parser.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/parser/parser.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/parser/parser_nn.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/parser/parser_nn.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/parser/parser_nn_trainer.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/parsito/README  \n",
            "  inflating: udpipe-1.2.0-bin/src/Makefile.include  \n",
            "  inflating: udpipe-1.2.0-bin/src/Makefile  \n",
            "   creating: udpipe-1.2.0-bin/src/trainer/\n",
            "  inflating: udpipe-1.2.0-bin/src/trainer/trainer_morphodita_parsito.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/trainer/trainer_morphodita_parsito.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/trainer/trainer.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/trainer/training_failure.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/trainer/training_failure.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/trainer/trainer.cpp  \n",
            " extracting: udpipe-1.2.0-bin/src/.clang_complete  \n",
            "  inflating: udpipe-1.2.0-bin/src/common.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/.editorconfig  \n",
            "   creating: udpipe-1.2.0-bin/src/model/\n",
            "  inflating: udpipe-1.2.0-bin/src/model/model_morphodita_parsito.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/model/model_morphodita_parsito.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/model/pipeline.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/model/evaluator.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/model/model.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/model/evaluator.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/model/model.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/model/pipeline.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/udpipe.cpp  \n",
            "   creating: udpipe-1.2.0-bin/src/morphodita/\n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/LICENSE  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/Makefile.include  \n",
            "   creating: udpipe-1.2.0-bin/src/morphodita/morpho/\n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/czech_morpho.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/english_morpho_guesser_encoder.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/morpho_prefix_guesser_encoder.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/english_morpho.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/small_stringops.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/czech_lemma_addinfo.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/morpho_statistical_guesser.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/persistent_unordered_map.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/raw_morpho_dictionary_reader.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/tag_filter.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/generic_morpho.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/Makefile  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/external_morpho_encoder.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/morpho_dictionary.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/generic_morpho.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/raw_morpho_dictionary_reader.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/english_morpho_guesser.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/english_morpho_guesser.rl  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/persistent_unordered_map_encoder.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/english_morpho_encoder.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/external_morpho.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/morpho.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/morpho_prefix_guesser.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/english_morpho_guesser.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/external_morpho_encoder.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/morpho_statistical_guesser_encoder.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/external_morpho.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/morpho_statistical_guesser_trainer.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/czech_morpho_encoder.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/czech_morpho_encoder.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/english_morpho_guesser_encoder.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/english_morpho.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/generic_morpho_encoder.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/generic_morpho_encoder.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/morpho_statistical_guesser.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/morpho_dictionary_encoder.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/morpho_ids.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/morpho_statistical_guesser_trainer.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/czech_morpho.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/morpho.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/morpho_prefix_guesser_encoder.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/english_morpho_encoder.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/tag_filter.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/casing_variants.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/english_lemma_addinfo.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/generic_lemma_addinfo.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/morpho/morpho_statistical_guesser_encoder.h  \n",
            "   creating: udpipe-1.2.0-bin/src/morphodita/derivator/\n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/derivator/derivator.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/derivator/derivator_dictionary_encoder.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/derivator/derivator_dictionary_encoder.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/derivator/derivator_dictionary.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/derivator/derivator_dictionary.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/derivator/derivation_formatter.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/derivator/derivation_formatter.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/CHANGES  \n",
            "   creating: udpipe-1.2.0-bin/src/morphodita/tokenizer/\n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/tokenizer.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/unicode_tokenizer.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/vertical_tokenizer.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/generic_tokenizer_factory_encoder.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/czech_tokenizer.rl  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/gru_tokenizer_network_trainer.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/english_tokenizer.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/gru_tokenizer_factory.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/tokenizer.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/ragel_tokenizer.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/tokenizer_factory.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/czech_tokenizer.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/gru_tokenizer_network.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/generic_tokenizer_factory.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/gru_tokenizer_network.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/tokenizer_ids.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/generic_tokenizer.rl  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/generic_tokenizer.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/unicode_tokenizer.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/generic_tokenizer_factory_encoder.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/Makefile  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/ragel_tokenizer.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/gru_tokenizer.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/gru_tokenizer_trainer.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/tokenizer_factory.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/english_tokenizer.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/generic_tokenizer_factory.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/gru_tokenizer.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/vertical_tokenizer.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/generic_tokenizer.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/gru_tokenizer_trainer.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/ragel_tokenizer.rl  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/czech_tokenizer.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/gru_tokenizer_factory.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tokenizer/english_tokenizer.rl  \n",
            "   creating: udpipe-1.2.0-bin/src/morphodita/tagset_converter/\n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagset_converter/tagset_converter.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagset_converter/strip_lemma_id_tagset_converter.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagset_converter/tagset_converter.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagset_converter/pdt_to_conll2009_tagset_converter.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagset_converter/pdt_to_conll2009_tagset_converter.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagset_converter/identity_tagset_converter.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagset_converter/strip_lemma_comment_tagset_converter.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagset_converter/strip_lemma_comment_tagset_converter.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagset_converter/strip_lemma_id_tagset_converter.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagset_converter/identity_tagset_converter.h  \n",
            "   creating: udpipe-1.2.0-bin/src/morphodita/version/\n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/version/version.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/version/version.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/README  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/AUTHORS  \n",
            "   creating: udpipe-1.2.0-bin/src/morphodita/tagger/\n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagger/generic_elementary_features.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagger/czech_elementary_features.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagger/perceptron_tagger_trainer.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagger/feature_sequences_optimizer.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagger/elementary_features_encoder.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagger/feature_sequences_encoder.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagger/training_maps.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagger/vli.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagger/tagger_trainer.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagger/tagger.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagger/feature_sequences.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagger/viterbi.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagger/elementary_features.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagger/tagger.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagger/tagger_ids.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagger/perceptron_tagger.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/morphodita/tagger/conllu_elementary_features.h  \n",
            "   creating: udpipe-1.2.0-bin/src/unilib/\n",
            "  inflating: udpipe-1.2.0-bin/src/unilib/CHANGES  \n",
            "  inflating: udpipe-1.2.0-bin/src/unilib/utf8.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/unilib/README  \n",
            "  inflating: udpipe-1.2.0-bin/src/unilib/version.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/unilib/unicode.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/unilib/AUTHORS  \n",
            "  inflating: udpipe-1.2.0-bin/src/unilib/utf8.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/unilib/utf16.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/unilib/uninorms.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/unilib/utf16.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/unilib/uninorms.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/unilib/LICENSE  \n",
            "  inflating: udpipe-1.2.0-bin/src/unilib/unicode.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/unilib/unistrip.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/unilib/unistrip.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/unilib/Makefile.include  \n",
            "  inflating: udpipe-1.2.0-bin/src/unilib/version.h  \n",
            "   creating: udpipe-1.2.0-bin/src/utils/\n",
            "  inflating: udpipe-1.2.0-bin/src/utils/getwhole.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/string_piece.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/threadsafe_stack.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/compressor.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/compressor_save.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/AUTHORS  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/options.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/parse_int.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/url_detector.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/CHANGES  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/compressor_load.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/getpara.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/parse_double.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/new_unique_ptr.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/xml_encoded.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/README  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/named_values.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/process_args.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/pointer_decoder.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/iostreams.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/binary_decoder.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/binary_encoder.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/common.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/LICENSE  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/threadsafe_resource_loader.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/url_detector.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/split.h  \n",
            "  inflating: udpipe-1.2.0-bin/src/utils/options.cpp  \n",
            "   creating: udpipe-1.2.0-bin/src/version/\n",
            "  inflating: udpipe-1.2.0-bin/src/version/version.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src/version/version.h  \n",
            "  inflating: udpipe-1.2.0-bin/CHANGES  \n",
            "   creating: udpipe-1.2.0-bin/src_lib_only/\n",
            "  inflating: udpipe-1.2.0-bin/src_lib_only/udpipe.cpp  \n",
            "  inflating: udpipe-1.2.0-bin/src_lib_only/udpipe.h  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkh40wo84R3q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ec97407-bb94-4adf-e758-bb2b148809d4"
      },
      "source": [
        "!ls udpipe-1.2.0-bin/"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUTHORS      bin-linux64  bin-win64  LICENSE\t  MANUAL.pdf  src_lib_only\n",
            "bindings     bin-osx\t  CHANGES    MANUAL\t  README\n",
            "bin-linux32  bin-win32\t  INSTALL    MANUAL.html  src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz2_Ky_U4R3_"
      },
      "source": [
        "Внутри бинарники для всех популярных ОС, выбираем свою. У меня путь к бинарнику такой: `udpipe-1.2.0-bin/bin-linux64`.\n",
        "\n",
        "Синтаксис:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW6K8EC34R4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e4b9aeb-8f01-40c9-908f-5d8da227d6ca"
      },
      "source": [
        "! udpipe-1.2.0-bin/bin-linux64/udpipe --help"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage: udpipe-1.2.0-bin/bin-linux64/udpipe [running_opts] model_file [input_files]\n",
            "       udpipe-1.2.0-bin/bin-linux64/udpipe --train [training_opts] model_file [input_files]\n",
            "       udpipe-1.2.0-bin/bin-linux64/udpipe --detokenize [detokenize_opts] raw_text_file [input_files]\n",
            "Running opts: --accuracy (measure accuracy only)\n",
            "              --input=[conllu|generic_tokenizer|horizontal|vertical]\n",
            "              --immediate (process sentences immediately during loading)\n",
            "              --outfile=output file template\n",
            "              --output=[conllu|epe|matxin|horizontal|plaintext|vertical]\n",
            "              --tokenize (perform tokenization)\n",
            "              --tokenizer=tokenizer options, implies --tokenize\n",
            "              --tag (perform tagging)\n",
            "              --tagger=tagger options, implies --tag\n",
            "              --parse (perform parsing)\n",
            "              --parser=parser options, implies --parse\n",
            "Training opts: --method=[morphodita_parsito] which method to use\n",
            "               --heldout=heldout data file name\n",
            "               --tokenizer=tokenizer options\n",
            "               --tagger=tagger options\n",
            "               --parser=parser options\n",
            "Detokenize opts: --outfile=output file template\n",
            "Generic opts: --version\n",
            "              --help\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eik_OPtS4R4e"
      },
      "source": [
        "Типичная команда для парсинга будет выглядеть так:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sUY8M9k4R4i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83d612a2-78d4-4fc8-806b-ae01a3c93c35"
      },
      "source": [
        "with open('example.txt', 'w') as f:\n",
        "    f.write(example)\n",
        "\n",
        "! udpipe-1.2.0-bin/bin-linux64/udpipe --tokenize --tag --parse\\\n",
        "  russian-ud-2.0-170801.udpipe example.txt > parsed_example.conllu\n",
        "! cat parsed_example.conllu"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading UDPipe model: done.\n",
            "# newdoc id = example.txt\n",
            "# newpar\n",
            "# sent_id = 1\n",
            "# text = Эти типы стали есть в цеху.\n",
            "1\tЭти\tЭТОТ\tDET\tDT\tAnimacy=Inan|Case=Nom|Number=Plur\t2\tdet\t_\t_\n",
            "2\tтипы\tТИП\tNOUN\tNN\tAnimacy=Inan|Case=Nom|Gender=Masc|Number=Plur\t4\tnsubj\t_\t_\n",
            "3\tстали\tСТАТЬ\tAUX\tVBC\tAspect=Perf|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin\t4\taux:pass\t_\t_\n",
            "4\tесть\tБЫТЬ\tVERB\tVBC\tAspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t0\troot\t_\t_\n",
            "5\tв\tВ\tADP\tIN\t_\t6\tcase\t_\t_\n",
            "6\tцеху\tцеху\tNOUN\tNN\tAnimacy=Inan|Case=Acc|Gender=Fem|Number=Sing\t4\tobl\t_\tSpaceAfter=No\n",
            "7\t.\t.\tPUNCT\t.\t_\t4\tpunct\t_\tSpacesAfter=\\n\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTYpvt7w4R43"
      },
      "source": [
        "Если нас интересует только тэггинг:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIXXJyJx4R47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "644407ef-89a2-40ce-97b8-b7d9e3b27c37"
      },
      "source": [
        "with open('example.txt', 'w') as f:\n",
        "    f.write(example)\n",
        "\n",
        "! udpipe-1.2.0-bin/bin-linux64/udpipe --tokenize --tag\\\n",
        "  russian-ud-2.0-170801.udpipe example.txt > tagged_example.conllu\n",
        "! cat tagged_example.conllu"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading UDPipe model: done.\n",
            "# newdoc id = example.txt\n",
            "# newpar\n",
            "# sent_id = 1\n",
            "# text = Эти типы стали есть в цеху.\n",
            "1\tЭти\tЭТОТ\tDET\tDT\tAnimacy=Inan|Case=Nom|Number=Plur\t_\t_\t_\t_\n",
            "2\tтипы\tТИП\tNOUN\tNN\tAnimacy=Inan|Case=Nom|Gender=Masc|Number=Plur\t_\t_\t_\t_\n",
            "3\tстали\tСТАТЬ\tAUX\tVBC\tAspect=Perf|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin\t_\t_\t_\t_\n",
            "4\tесть\tБЫТЬ\tVERB\tVBC\tAspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t_\t_\t_\t_\n",
            "5\tв\tВ\tADP\tIN\t_\t_\t_\t_\t_\n",
            "6\tцеху\tцеху\tNOUN\tNN\tAnimacy=Inan|Case=Acc|Gender=Fem|Number=Sing\t_\t_\t_\tSpaceAfter=No\n",
            "7\t.\t.\tPUNCT\t.\t_\t_\t_\t_\tSpacesAfter=\\n\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JusTjNEh4R5Q"
      },
      "source": [
        "(Ну а потом снова считываем проанализированные предложения питоном).\n",
        "\n",
        "Вот два способа работать с UDPipe. Choose your fighter! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-R6hlXE4R5U"
      },
      "source": [
        "#### Задание\n",
        "\n",
        "Напишите функцию, которая проверяет, не состоит ли предложение из большого числа однородных предложений."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPHeWPEX4R5Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa0w67clQymz"
      },
      "source": [
        "##DeepPavlov BERT-based Syntactic Parsing\n",
        "We use BERT as the lowest layer of our model (the embedder). To extract syntactic information we apply the biaffine network of [Dozat, Manning, 2017]. For each sentence of length K this network produces two outputs: the first is an array of shape K*(K+1), where i-th row is the probability distribution of the head of i-th word over the sentence elements. The 0-th element of this distribution is the probability of the word to be a root of the sentence. The second output of the network is of shape K*D, where D is the number of possible dependency labels.\n",
        "\n",
        "The easiest way to obtain a tree is simply to return the head with the highest probability for each word in the sentence. However, the graph obtained in such a way may fail to be a valid tree: it may either contain a cycle or have multiple nodes with head at position 0. Therefore we apply the well-known Chu-Liu-Edmonds algorithm for minimal spanning tree to return the optimal tree, using the open-source modification from dependency_decoding package <https://github.com/andersjo/dependency_decoding>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xJNMbuJQ9gK",
        "outputId": "7e5c6536-33f9-4f70-ae0a-d7b5e1a41b93"
      },
      "source": [
        "#!pip install deeppavlov\n",
        "!python -m deeppavlov install syntax_ru_syntagrus_bert"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-11-08 09:18:33.591 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'syntax_ru_syntagrus_bert' as '/usr/local/lib/python3.7/dist-packages/deeppavlov/configs/syntax/syntax_ru_syntagrus_bert.json'\n",
            "Collecting git+https://github.com/deepmipt/bert.git@feat/multi_gpu\n",
            "  Cloning https://github.com/deepmipt/bert.git (to revision feat/multi_gpu) to /tmp/pip-req-build-2kcp_nxq\n",
            "  Running command git clone -q https://github.com/deepmipt/bert.git /tmp/pip-req-build-2kcp_nxq\n",
            "Collecting git+https://github.com/andersjo/dependency_decoding.git@79510908223b93bd4c1fb0409a2a66dd75577c2c\n",
            "  Cloning https://github.com/andersjo/dependency_decoding.git (to revision 79510908223b93bd4c1fb0409a2a66dd75577c2c) to /tmp/pip-req-build-goal38un\n",
            "  Running command git clone -q https://github.com/andersjo/dependency_decoding.git /tmp/pip-req-build-goal38un\n",
            "  Running command git rev-parse -q --verify 'sha^79510908223b93bd4c1fb0409a2a66dd75577c2c'\n",
            "  Running command git fetch -q https://github.com/andersjo/dependency_decoding.git 79510908223b93bd4c1fb0409a2a66dd75577c2c\n",
            "Requirement already satisfied: tensorflow==1.15.5 in /usr/local/lib/python3.7/dist-packages (1.15.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.17.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.0.8)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.12.1)\n",
            "Requirement already satisfied: h5py<=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (2.10.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.37.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.3.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.18.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.15.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.41.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqglYsW6lWWv",
        "outputId": "91986e18-9f54-4db3-8a1f-09bf42db8279"
      },
      "source": [
        "!pip install russian_tagsets\n",
        "from deeppavlov import build_model, configs\n",
        "model = build_model(configs.syntax.syntax_ru_syntagrus_bert, download=True)\n",
        "sentences = [\"Я шёл домой по незнакомой улице.\", \"Девушка пела в церковном хоре.\"]\n",
        "for parse in model(sentences):\n",
        "    print(parse, end=\"\\n\\n\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: russian_tagsets in /usr/local/lib/python3.7/dist-packages (0.6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/cryptography/hazmat/backends/openssl/x509.py:18: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
            "  utils.DeprecatedIn35,\n",
            "2021-11-08 09:21:12.345 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/deeppavlov_data/morpho_tagger/UD2.3/ru_syntagrus.tar.gz download because of matching hashes\n",
            "2021-11-08 09:21:32.654 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/deeppavlov_data/syntax_parser/syntax_ru_syntagrus_bert.tar.gz download because of matching hashes\n",
            "2021-11-08 09:21:52.566 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_v1.tar.gz download because of matching hashes\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Package perluniprops is already up-to-date!\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-11-08 09:21:58.806 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/syntax_ru_syntagrus/deps.dict]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:236: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:314: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
            "\n",
            "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:75: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/layers/tf_layers.py:161: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/layers/tf_layers.py:181: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/layers/tf_layers.py:185: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/layers/tf_layers.py:185: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/syntax_parser/network.py:257: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:131: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:244: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:249: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-11-08 09:22:23.550 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/syntax_ru_syntagrus/model_joint]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/syntax_ru_syntagrus/model_joint\n",
            "1\tЯ\t_\t_\t_\t_\t2\tnsubj\t_\t_\n",
            "2\tшёл\t_\t_\t_\t_\t0\troot\t_\t_\n",
            "3\tдомой\t_\t_\t_\t_\t2\tadvmod\t_\t_\n",
            "4\tпо\t_\t_\t_\t_\t6\tcase\t_\t_\n",
            "5\tнезнакомой\t_\t_\t_\t_\t6\tamod\t_\t_\n",
            "6\tулице\t_\t_\t_\t_\t2\tobl\t_\t_\n",
            "7\t.\t_\t_\t_\t_\t2\tpunct\t_\t_\n",
            "\n",
            "\n",
            "1\tДевушка\t_\t_\t_\t_\t2\tnsubj\t_\t_\n",
            "2\tпела\t_\t_\t_\t_\t0\troot\t_\t_\n",
            "3\tв\t_\t_\t_\t_\t5\tcase\t_\t_\n",
            "4\tцерковном\t_\t_\t_\t_\t5\tamod\t_\t_\n",
            "5\tхоре\t_\t_\t_\t_\t2\tobl\t_\t_\n",
            "6\t.\t_\t_\t_\t_\t2\tpunct\t_\t_\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gC46TLR_mOwP",
        "outputId": "b36f04db-38e9-4858-ed10-82be2768faa1"
      },
      "source": [
        "model = build_model(\"ru_syntagrus_joint_parsing\", download=True)\n",
        "sentences = [\"Я шёл домой по незнакомой улице.\", \"Девушка пела в церковном хоре.\"]\n",
        "for parse in model(sentences):\n",
        "   print(parse, end=\"\\n\\n\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-11-08 09:22:31.777 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'ru_syntagrus_joint_parsing' as '/usr/local/lib/python3.7/dist-packages/deeppavlov/configs/syntax/ru_syntagrus_joint_parsing.json'\n",
            "/usr/local/lib/python3.7/dist-packages/cryptography/hazmat/backends/openssl/x509.py:18: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
            "  utils.DeprecatedIn35,\n",
            "2021-11-08 09:22:51.197 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/deeppavlov_data/morpho_tagger/BERT/morpho_ru_syntagrus_bert.tar.gz download because of matching hashes\n",
            "2021-11-08 09:22:52.123 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/deeppavlov_data/morpho_tagger/UD2.3/ru_syntagrus.tar.gz download because of matching hashes\n",
            "2021-11-08 09:22:54.402 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/deeppavlov_data/syntax_parser/syntax_ru_syntagrus_bert.tar.gz download because of matching hashes\n",
            "2021-11-08 09:22:56.672 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_v1.tar.gz download because of matching hashes\n",
            "2021-11-08 09:22:57.105 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/morpho_ru_syntagrus/tag.dict]\n",
            "2021-11-08 09:23:18.138 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/morpho_ru_syntagrus/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/morpho_ru_syntagrus/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-11-08 09:23:20.76 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 52: No load path is set for UDPymorphyLemmatizer!\n",
            "2021-11-08 09:23:20.543 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/syntax_ru_syntagrus/deps.dict]\n",
            "2021-11-08 09:23:46.583 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/syntax_ru_syntagrus/model_joint]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/syntax_ru_syntagrus/model_joint\n",
            "1\tЯ\tя\tPRON\t_\tCase=Nom|Number=Sing|Person=1\t2\tnsubj\t_\t_\n",
            "2\tшёл\tидти\tVERB\t_\tAspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\t0\troot\t_\t_\n",
            "3\tдомой\tдомой\tADV\t_\tDegree=Pos\t2\tadvmod\t_\t_\n",
            "4\tпо\tпо\tADP\t_\t_\t6\tcase\t_\t_\n",
            "5\tнезнакомой\tнезнакомый\tADJ\t_\tCase=Dat|Degree=Pos|Gender=Fem|Number=Sing\t6\tamod\t_\t_\n",
            "6\tулице\tулица\tNOUN\t_\tAnimacy=Inan|Case=Dat|Gender=Fem|Number=Sing\t2\tobl\t_\t_\n",
            "7\t.\t.\tPUNCT\t_\t_\t2\tpunct\t_\t_\n",
            "\n",
            "1\tДевушка\tдевушка\tNOUN\t_\tAnimacy=Anim|Case=Nom|Gender=Fem|Number=Sing\t2\tnsubj\t_\t_\n",
            "2\tпела\tпеть\tVERB\t_\tAspect=Imp|Gender=Fem|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\t0\troot\t_\t_\n",
            "3\tв\tв\tADP\t_\t_\t5\tcase\t_\t_\n",
            "4\tцерковном\tцерковный\tADJ\t_\tCase=Loc|Degree=Pos|Gender=Masc|Number=Sing\t5\tamod\t_\t_\n",
            "5\tхоре\tхор\tNOUN\t_\tAnimacy=Inan|Case=Loc|Gender=Masc|Number=Sing\t2\tobl\t_\t_\n",
            "6\t.\t.\tPUNCT\t_\t_\t2\tpunct\t_\t_\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_rhmctJ4R51"
      },
      "source": [
        "## SVO-triples\n",
        "\n",
        "С помощью синтаксического парсинга можно выделять из предложений тройки субъект-объект-глагол, которые можно использовать для извлечения информации из текста.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxolHH_V4R54"
      },
      "source": [
        "sent = \"\"\"1\tСобянин\t_\tNOUN\t_\tAnimacy=Anim|Case=Nom|Gender=Masc|Number=Sing|fPOS=NOUN++\t2\tnsubj\t_\t_\n",
        "2\tоткрыл\t_\tVERB\t_\tAspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act|fPOS=VERB++\t0\tROOT\t_\t_\n",
        "3\tновый\t_\tADJ\t_\tAnimacy=Inan|Case=Acc|Degree=Pos|Gender=Masc|Number=Sing|fPOS=ADJ++\t4\tamod\t_\t_\n",
        "4\tпарк\t_\tNOUN\t_\tAnimacy=Inan|Case=Acc|Gender=Masc|Number=Sing|fPOS=NOUN++\t2\tdobj\t_\t_\n",
        "5\tи\t_\tCONJ\t_\tfPOS=CONJ++\t4\tcc\t_\t_\n",
        "6\tдетскую\t_\tADJ\t_\tCase=Acc|Degree=Pos|Gender=Fem|Number=Sing|fPOS=ADJ++\t7\tamod\t_\t_\n",
        "7\tплощадку\t_\tNOUN\t_\tAnimacy=Inan|Case=Acc|Gender=Fem|Number=Sing|fPOS=NOUN++\t4\tconj\t_\t_\n",
        "8\t.\t_\tPUNCT\t.\tfPOS=PUNCT++.\t2\tpunct\t_\t_\"\"\""
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcIJvRnF4R6K"
      },
      "source": [
        "Тройки слово-слово-связь:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHN8y5CP4R6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddce1dfe-1657-4399-cc47-c63a3c9df317"
      },
      "source": [
        "graph = DependencyGraph(tree_str=sent)\n",
        "graph\n",
        "list(graph.triples())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('открыл', 'VERB'), 'nsubj', ('Собянин', 'NOUN')),\n",
              " (('открыл', 'VERB'), 'dobj', ('парк', 'NOUN')),\n",
              " (('парк', 'NOUN'), 'amod', ('новый', 'ADJ')),\n",
              " (('парк', 'NOUN'), 'cc', ('и', 'CONJ')),\n",
              " (('парк', 'NOUN'), 'conj', ('площадку', 'NOUN')),\n",
              " (('площадку', 'NOUN'), 'amod', ('детскую', 'ADJ')),\n",
              " (('открыл', 'VERB'), 'punct', ('.', 'PUNCT'))]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eqvMO7H4R6h"
      },
      "source": [
        "Тройки субьект-объект-глагол:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1eRmoxP4R6k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73081fa6-6f99-4490-ffe6-9ee5f0d301ff"
      },
      "source": [
        "def get_sov(sent):\n",
        "    graph = DependencyGraph(tree_str=sent)\n",
        "    sov = {}\n",
        "    for triple in graph.triples():\n",
        "        if triple:\n",
        "            if triple[0][1] == 'VERB':\n",
        "                sov[triple[0][0]] = {'subj':'','obj':''}\n",
        "    for triple in graph.triples():\n",
        "        if triple:\n",
        "            if triple[1] == 'nsubj':\n",
        "                if triple[0][1] == 'VERB':\n",
        "                    sov[triple[0][0]]['subj']  = triple[2][0]\n",
        "            if triple[1] == 'dobj':\n",
        "                if triple[0][1] == 'VERB':\n",
        "                    sov[triple[0][0]]['obj'] = triple[2][0]\n",
        "    return sov\n",
        "\n",
        "sov = get_sov(sent)\n",
        "print(sov)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'открыл': {'subj': 'Собянин', 'obj': 'парк'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm0B87e34R60"
      },
      "source": [
        "#### Задание\n",
        "\n",
        "Измените код выше так, чтобы учитывались:\n",
        "    1. Однородные члены предложения \n",
        "        * (парк, площадка), (Германия, Швейцария)\n",
        "    2. Сложные сказуемые \n",
        "        * (начнет продавать), (запретил провозить)\n",
        "    3. Непрямые объекты\n",
        "        * (едет, Польшу), (спел, скандале)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHyhEXH84R68"
      },
      "source": [
        "example = \"\"\"\n",
        "1\tДалее\tдалее\tADV\t_\tDegree=Pos\t3\tadvmod\t_\t_\n",
        "2\tона\tона\tPRON\t_\tCase=Nom|Gender=Fem|Number=Sing|Person=3\t3\tnsubj\t_\t_\n",
        "3\tперебралась\tперебраться\tVERB\t_\tAspect=Perf|Gender=Fem|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Mid\t0\troot\t_\t_\n",
        "4\tв\tв\tADP\t_\t_\t5\tcase\t_\t_\n",
        "5\tБухарест\tБухарест\tPROPN\t_\tAnimacy=Inan|Case=Acc|Gender=Masc|Number=Sing\t3\tobl\t_\tSpaceAfter=No\n",
        "6\t,\t,\tPUNCT\t_\t_\t9\tpunct\t_\t_\n",
        "7\tа\tа\tCCONJ\t_\t_\t9\tcc\t_\t_\n",
        "8\tзатем\tзатем\tADV\t_\tDegree=Pos\t9\tadvmod\t_\t_\n",
        "9\tуехала\tуехать\tVERB\t_\tAspect=Perf|Gender=Fem|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\t3\tconj\t_\t_\n",
        "10\tв\tв\tADP\t_\t_\t11\tcase\t_\t_\n",
        "11\tПариж\tПариж\tPROPN\t_\tAnimacy=Inan|Case=Acc|Gender=Masc|Number=Sing\t9\tobl\t_\tSpaceAfter=No\n",
        "12\t.\t.\tPUNCT\t_\t_\t3\tpunct\t_\t_\"\"\""
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzZXuCiI4R7X"
      },
      "source": [
        "sents = []\n",
        "for sent1 in example.split('\\n\\n'):\n",
        "    # убираем комментарии\n",
        "    sent1 = '\\n'.join([line for line in sent1.split('\\n') if not line.startswith('#')])\n",
        "    # заменяем deprel для root\n",
        "    sent1 = sent1.replace('\\troot\\t', '\\tROOT\\t')\n",
        "    sents.append(sent1)\n",
        "\n",
        "def get_sov(sent):\n",
        "    graph = DependencyGraph(tree_str=sent)\n",
        "    sov = {}\n",
        "    for triple in graph.triples():\n",
        "        print(triple)\n",
        "        if triple:\n",
        "            if triple[0][1] == 'VERB':\n",
        "                sov[triple[0][0]] = {'subj':'','obj':''}\n",
        "    for triple in graph.triples():\n",
        "        if triple:\n",
        "            if triple[1] == 'nsubj':\n",
        "                if triple[0][1] == 'VERB':\n",
        "                    sov[triple[0][0]]['subj']  = triple[2][0]\n",
        "            if triple[1] == 'dobj' or triple[1] == 'obl':\n",
        "                if triple[0][1] == 'VERB':\n",
        "                    sov[triple[0][0]]['obj'] = triple[2][0]\n",
        "    return sov"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzMl2Dk74R7x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df02b1cc-ece7-4ea8-cdb4-25d9891011f7"
      },
      "source": [
        "triples = get_sov(sents[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(('перебралась', 'VERB'), 'advmod', ('Далее', 'ADV'))\n",
            "(('перебралась', 'VERB'), 'nsubj', ('она', 'PRON'))\n",
            "(('перебралась', 'VERB'), 'obl', ('Бухарест', 'PROPN'))\n",
            "(('Бухарест', 'PROPN'), 'case', ('в', 'ADP'))\n",
            "(('перебралась', 'VERB'), 'conj', ('уехала', 'VERB'))\n",
            "(('уехала', 'VERB'), 'punct', (',', 'PUNCT'))\n",
            "(('уехала', 'VERB'), 'cc', ('а', 'CCONJ'))\n",
            "(('уехала', 'VERB'), 'advmod', ('затем', 'ADV'))\n",
            "(('уехала', 'VERB'), 'obl', ('Париж', 'PROPN'))\n",
            "(('Париж', 'PROPN'), 'case', ('в', 'ADP'))\n",
            "(('перебралась', 'VERB'), 'punct', ('.', 'PUNCT'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wJd3Px64R8G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-GmoKC04R8Z"
      },
      "source": [
        "# Sentiment Analysis with Recursive Neural Network\n",
        "\n",
        "* [источник туториала](https://medium.com/@keisukeumezawa/chainer-tutorial-sentiment-analysis-with-recursive-neural-network-180ddde892a2)\n",
        "* [статья](https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf); архитектура описана в 4 секции\n",
        "* [демо с кликабельными картинками](http://nlp.stanford.edu:8080/sentiment/rntnDemo.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyTMcNyt4R8g"
      },
      "source": [
        "До сих пор мы смотрели на парсинг зависимостей, но для анализа тональности в этой части используется другой подход, *парсинг составляющих*, или *constituency parsing*. \n",
        "![Constituеncy parsing](constituency_parsing.png) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HehOl4a-4R8k"
      },
      "source": [
        "### Идея\n",
        "\n",
        "Сентимент предложения складывается из сентимента его составляющих, а для тех -- в свою очередь, из их составляющих.\n",
        "\n",
        "![sentiment recursive nn](sentiment_recursiveNN.png)\n",
        "\n",
        "(в датасете 5 классов тональности: --, -, 0, +, ++)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2qNNI9b4R8n"
      },
      "source": [
        "### Recursive Neural Network\n",
        "\n",
        "Это нейросети, которые работают с данными переменной длины, используя иерархические структуры (деревья).\n",
        "Скрытое состояние i-той вершины дерева вычисляются из скрытых состояний её левого и правого ребёнка:\n",
        "\n",
        "![recursive nn_formula](recursiveNN_formula.jpg)\n",
        "![recursive nn](recursiveNN.jpg)\n",
        "\n",
        "Векторные представления фраз (узлов дерева) подаются на вход слою-классификатору тональности и слою softmax (в обучающем датасете все составляющие размечены по тональности)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQYYuNNO4R8q"
      },
      "source": [
        "А теперь давайте посмотрим на код: [jupyter notebook](https://chainer-colab-notebook.readthedocs.io/en/latest/notebook/official_example/sentiment.html), [репозиторий](https://github.com/chainer/chainer/tree/master/examples/sentiment)."
      ]
    }
  ]
}